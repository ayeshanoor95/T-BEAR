{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center>Artifact Rejection using Support Vector Classifier</center></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%run -i utils.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "<h3><left>I. Data Processing & Feature Selection</left></h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load researcher and subject folders\n",
    "subjects = list()\n",
    "stephanie_folder = Path(\"C:\\\\Users\\\\peter\\\\git\\\\EEG-artifact-rejection\\\\artifact-rejection\\\\eeg-data\\\\Stephanie\")\n",
    "sub_folders = [os.path.join(stephanie_folder, file) for file in os.listdir(stephanie_folder)]\n",
    "\n",
    "# Use the median for each of the bad channels\n",
    "stephanie_bad_chan = {\n",
    "    'Rew_605_rest': ['Fp1', 'Fp2'],\n",
    "    'Rew_609_rest': ['F3', 'F7', 'Fp1'],\n",
    "    'Rew_611_rest': ['Fp2', 'T3'],\n",
    "    'Rew_613_rest': ['F7', 'Fp2'],\n",
    "    'Rew_614_rest': ['C3', 'CZ', 'F3', 'F7', 'F8', 'FZ', 'Fp1', 'O1', 'P3', 'PZ', 'T3', 'T5'],\n",
    "    'Rew_615_rest': ['C4', 'F4', 'F8', 'Fp2', 'O2', 'P4', 'T4', 'T6'],\n",
    "    'Rew_619_rest': ['F4'],\n",
    "    'Rew_622_rest': ['F7'],\n",
    "    'Rew_624_rest': ['F3', 'F7', 'Fp1', 'T3', 'T4', 'T5', 'T6'],\n",
    "    'Rew_626_rest': ['F3', 'F4', 'T3', 'T4', 'T5'],\n",
    "    'Rew_701_rest': ['C4', 'F7', 'F8', 'O1', 'O2', 'T3', 'T3', 'T4', 'T5'],\n",
    "    'Rew_702_rest': ['C3', 'F3'],\n",
    "    'Rew_703_rest': ['F4', 'F7', 'F8', 'Fp2', 'T3', 'T4', 'T6'],\n",
    "    'Rew_704_rest': ['C3'],\n",
    "    'Rew_706_rest': ['T4']\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sub in sub_folders:\n",
    "    files = os.listdir(Path(sub))\n",
    "    temp_sub_files = dict()\n",
    "    for file in files:\n",
    "        file_path = os.path.join(Path(sub), file)\n",
    "        if 'epoch' in file:\n",
    "            temp_sub_files['epoch'] = file_path\n",
    "        if 'reject' in file:\n",
    "             temp_sub_files['reject'] = file_path\n",
    "        elif 'stages' in file:\n",
    "            temp_sub_files['stage'] = file_path\n",
    "    subjects.append(temp_sub_files)\n",
    "\n",
    "three_fourth = int((len(subjects) * 0.75) // 1)\n",
    "\n",
    "x_train = subjects[:three_fourth]\n",
    "x_test = subjects[three_fourth:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><left>II. Model Training</left></h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize classifier\n",
    "clfSVC = LinearSVC(penalty='l2', loss='hinge', dual=True, tol=0.0001, C=10.0, multi_class='ovr', fit_intercept=True, intercept_scaling=1, class_weight=None, verbose=1, random_state=42, max_iter=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model training\n",
    "for sub_ in x_train:\n",
    "    file_path = sub_['epoch']\n",
    "    mat_reject = sub_['reject']\n",
    "    mat_stage = sub_['stage']\n",
    "\n",
    "    files = load_subject_dir(file_path, mat_reject, mat_stage)\n",
    "    epochs = files['epochs']\n",
    "    rejects = files['rejects']\n",
    "\n",
    "    # Clean data\n",
    "    index, scaling_time, scalings = ['epoch', 'time'], 1e3, dict(grad=1e13)\n",
    "    df = epochs.to_data_frame(\n",
    "        picks=None, scalings=scalings, scaling_time=scaling_time, index=index)\n",
    "    df_epochs = df.groupby('epoch').mean()\n",
    "\n",
    "    try:\n",
    "        stages = files['stages']\n",
    "        df_epochs['stage'] = stages\n",
    "    except Exception as ex:\n",
    "        print(ex)\n",
    "        pass\n",
    "\n",
    "    df_epochs = df.groupby('epoch').mean()\n",
    "    X, y = df_epochs.values, rejects\n",
    "    X, y_true = X, y\n",
    "    clfSVC.fit(X, y_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><left>III. Model Testing & Evaluation</left></h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Precision** _(how many selected items are relevant?)_:\n",
    "\n",
    "$$\\frac{\\text{True Positives}}{\\text{Trust Positives + False Positives}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Recall** _(How many relevant items are selected?)_:\n",
    "\n",
    "$$\\frac{\\text{True Positives}}{\\text{Trust Positives + False Negatives}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **F1 Score** _(weighted average of Precision and Recall)_:\n",
    "\n",
    "$$\\frac{2 \\cdot (\\text{Recall} \\cdot \\text{Precision})}{\\text{Recall} + \\text{Precision}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model testing\n",
    "for sub__ in x_test:\n",
    "    file_path = sub__['epoch']\n",
    "    mat_reject = sub__['reject']\n",
    "    mat_stage = sub__['stage']\n",
    "\n",
    "    files = load_subject_dir(file_path, mat_reject, mat_stage)\n",
    "    epochs = files['epochs']\n",
    "    rejects = files['rejects']\n",
    "\n",
    "    # Clean data\n",
    "    index, scaling_time, scalings = ['epoch', 'time'], 1e3, dict(grad=1e13)\n",
    "    df = epochs.to_data_frame(\n",
    "        picks=None, scalings=scalings, scaling_time=scaling_time, index=index)\n",
    "    df_epochs = df.groupby('epoch').mean()\n",
    "\n",
    "    try:\n",
    "        stages = files['stages']\n",
    "        df_epochs['stage'] = stages\n",
    "    except Exception as ex:\n",
    "        print(ex)\n",
    "        pass\n",
    "\n",
    "    df_epochs = df.groupby('epoch').mean()\n",
    "    X, y = df_epochs.values, rejects\n",
    "    X, y_true = X, y\n",
    "    y_pred = clfSVC.predict(X)\n",
    "\n",
    "    print(\"\\tRecall: %1.3f\" % recall_score(y_true, y_pred))\n",
    "    print(\"\\tF1: %1.3f\\n\" % f1_score(y_true, y_pred))"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
