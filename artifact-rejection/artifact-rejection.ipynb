{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from pathlib import Path\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import mne\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.io\n",
    "from sklearn.ensemble import IsolationForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set file paths:\n",
    "print(\"Loading file paths...\")\n",
    "file_path = str(Path(r'eeg-data/601/Rew_601_rest_bb_epoch.set'))\n",
    "mat_reject = str(Path(r'eeg-data/601/Rew_601_rest_reject_rmm.mat'))\n",
    "mat_stage = str(Path(r'eeg-data/601/Rew_601_rest_stages.mat'))\n",
    "print(\"Loaded file paths successfully!\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load epochs file:\n",
    "print(\"Loading files...\")\n",
    "try:\n",
    "    epochs = mne.io.read_epochs_eeglab(file_path)\n",
    "except:\n",
    "    epochs = mne.io.read_raw_eeglab(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load sleep stages & other files:\n",
    "try:\n",
    "    sleep_file = scipy.io.loadmat(mat_stage)\n",
    "    sleep = sleep_file['stages'].flatten()\n",
    "except FileNotFoundError:\n",
    "    pass\n",
    "finally:\n",
    "    reject_file = scipy.io.loadmat(mat_reject)\n",
    "    reject = reject_file['reject'].flatten()\n",
    "print(\"Loaded files successfully!\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to and clean DataFrame:\n",
    "print(\"Cleaning data...\")\n",
    "df = epochs.to_data_frame()\n",
    "columns, df = sorted(list(df.columns)), df.reset_index()\n",
    "\n",
    "try: \n",
    "    df = df.drop(['condition'], axis=1)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "cleaned_columns = ['time']\n",
    "if 'epoch' in list(df.columns):\n",
    "    cleaned_columns += ['epoch']\n",
    "\n",
    "cleaned_columns += columns\n",
    "df = df[cleaned_columns]\n",
    "df_ = df.copy()\n",
    "print(\"Cleaned data successfully!\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select values from columns for IForest:\n",
    "print(\"Preparing data for IForest algorithm...\")\n",
    "value_columns = list(df.columns)\n",
    "\n",
    "try:\n",
    "    if 'time' in value_columns:\n",
    "        value_columns.remove('time')\n",
    "    if 'epoch' in value_columns:\n",
    "        value_columns.remove('epoch')\n",
    "except:\n",
    "    pass\n",
    "\n",
    "df_values = df_[value_columns]\n",
    "print(\"Data prepared successfully!\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run IForest:\n",
    "print(\"Running IForest algorithm...\")\n",
    "X = df_values\n",
    "clfIF = IsolationForest(random_state=42, contamination=0.00001, n_jobs=3)\n",
    "clfIF.fit(X)\n",
    "pred_train, pred_test = clfIF.predict(X), clfIF.predict(X)\n",
    "count_train, count_test = np.unique(ar=pred_train, return_counts=True), np.unique(ar=pred_test, return_counts=True)\n",
    "index_train, index_test = [i for i,x in enumerate(pred_train) if x == -1] , [i for i,x in enumerate(pred_test) if x == -1]\n",
    "df_IF = df_.loc[index_test]\n",
    "num_artifacts_pair = count_train[1][0], count_test[1][0]\n",
    "num_artifacts = num_artifacts_pair[1]\n",
    "total_pts = count_train[1][1], count_test[1][1]\n",
    "total_artifacts = np.count_nonzero(reject)\n",
    "accuracy_percent = num_artifacts / total_artifacts * 100\n",
    "print(\"IForest algorithm ran successfully!\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Performance: {accuracy_percent}%\")\n",
    "print(f\"{num_artifacts} artifacts detected out of {total_artifacts} artifacts total.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
