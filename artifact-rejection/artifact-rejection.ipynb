{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%run -i utils.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "<h3><left>I. Data Wrangling</left></h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the median for each of the bad channels\n",
    "stephanie_bad_chan = {\n",
    "    'Rew_605_rest': ['Fp1', 'Fp2'],\n",
    "    'Rew_609_rest': ['F3', 'F7', 'Fp1'],\n",
    "    'Rew_611_rest': ['Fp2', 'T3'],\n",
    "    'Rew_613_rest': ['F7', 'Fp2'],\n",
    "    'Rew_614_rest': ['C3', 'CZ', 'F3', 'F7', 'F8', 'FZ', 'Fp1', 'O1', 'P3', 'PZ', 'T3', 'T5'],\n",
    "    'Rew_615_rest': ['C4', 'F4', 'F8', 'Fp2', 'O2', 'P4', 'T4', 'T6'],\n",
    "    'Rew_619_rest': ['F4'],\n",
    "    'Rew_622_rest': ['F7'],\n",
    "    'Rew_624_rest': ['F3', 'F7', 'Fp1', 'T3', 'T4', 'T5', 'T6'],\n",
    "    'Rew_626_rest': ['F3', 'F4', 'T3', 'T4', 'T5'],\n",
    "    'Rew_701_rest': ['C4', 'F7', 'F8', 'O1', 'O2', 'T3', 'T3', 'T4', 'T5'],\n",
    "    'Rew_702_rest': ['C3', 'F3'],\n",
    "    'Rew_703_rest': ['F4', 'F7', 'F8', 'Fp2', 'T3', 'T4', 'T6'],\n",
    "    'Rew_704_rest': ['C3'],\n",
    "    'Rew_706_rest': ['T4']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load researcher and subject folders\n",
    "subjects = dict()\n",
    "stephanie_folder = Path(\"C:\\\\Users\\\\peter\\\\git\\\\EEG-artifact-rejection\\\\artifact-rejection\\\\eeg-data\\\\Stephanie\")\n",
    "sub_folders = [[file, os.path.join(stephanie_folder, file)] for file in os.listdir(stephanie_folder)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4><left>Data Architecture</left></h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sub in sub_folders:\n",
    "    sub_id, path_ = sub[0], sub[1]\n",
    "    files = os.listdir(Path(path_))\n",
    "    sub_files = dict()\n",
    "    for file in files:\n",
    "        full_path = os.path.join(Path(path_), file)\n",
    "        if 'epoch' in file:\n",
    "            sub_files['epoch'] = full_path\n",
    "        if 'reject' in file:\n",
    "            sub_files['reject'] = full_path\n",
    "        elif 'stages' in file:\n",
    "            sub_files['stage'] = full_path\n",
    "    subjects[sub_id] = sub_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4><left>Data Processing</left></h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sub_ in subjects.keys():\n",
    "    file_path = subjects[sub_]['epoch']\n",
    "    mat_reject = subjects[sub_]['reject']\n",
    "    mat_stage = subjects[sub_]['stage']\n",
    "\n",
    "    files = load_subject_dir(file_path, mat_reject, mat_stage)\n",
    "    epochs = files['epochs']\n",
    "    rejects = files['rejects']\n",
    "\n",
    "    # Clean data\n",
    "    index, scaling_time, scalings = ['epoch', 'time'], 1e3, dict(grad=1e13)\n",
    "    df = epochs.to_data_frame(\n",
    "        picks=None, scalings=scalings, scaling_time=scaling_time, index=index)\n",
    "    df_epochs = df.groupby('epoch').mean()\n",
    "\n",
    "    try:\n",
    "        stages = files['stages']\n",
    "        df_epochs['stage'] = stages\n",
    "    except Exception as ex:\n",
    "        print(ex)\n",
    "        pass\n",
    "\n",
    "    df_epochs = df.groupby('epoch').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><left>II. Model Selection & Training</left></h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clfSVC = LinearSVC(penalty='l2', loss='hinge', dual=True, tol=0.0001, C=10.0, multi_class='ovr', fit_intercept=True,\n",
    "                   intercept_scaling=1, class_weight=None, verbose=1, random_state=42, max_iter=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4><left>Cross Validation</left></h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = df_epochs.values, rejects\n",
    "tscv = TimeSeriesSplit(n_splits=3)\n",
    "clf_score = []\n",
    "\n",
    "for train_index, test_index in tscv.split(df_epochs):\n",
    "    X_train, y_train = X[train_index], y[test_index]\n",
    "    clfSVC.fit(X_train, y_train)\n",
    "    clfSVC.predict(X_train)\n",
    "    clf_score += clfSVC.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><left>III. Model Testing & Evaluation</left></h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Precision** _(how many selected items are relevant?)_:\n",
    "\n",
    "$$\\frac{\\text{True Positives}}{\\text{Trust Positives + False Positives}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Recall** _(how many relevant items are selected?)_:\n",
    "\n",
    "$$\\frac{\\text{True Positives}}{\\text{Trust Positives + False Negatives}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **F1 Score** _(weighted average of Precision and Recall)_:\n",
    "\n",
    "$$\\frac{2 \\cdot (\\text{Recall} \\cdot \\text{Precision})}{\\text{Recall} + \\text{Precision}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model testing\n",
    "for sub__ in x_test:\n",
    "    file_path = sub__['epoch']\n",
    "    mat_reject = sub__['reject']\n",
    "    mat_stage = sub__['stage']\n",
    "\n",
    "    files = load_subject_dir(file_path, mat_reject, mat_stage)\n",
    "    epochs = files['epochs']\n",
    "    rejects = files['rejects']\n",
    "\n",
    "    # Clean data\n",
    "    index, scaling_time, scalings = ['epoch', 'time'], 1e3, dict(grad=1e13)\n",
    "    df = epochs.to_data_frame(\n",
    "        picks=None, scalings=scalings, scaling_time=scaling_time, index=index)\n",
    "    df_epochs = df.groupby('epoch').mean()\n",
    "\n",
    "    try:\n",
    "        stages = files['stages']\n",
    "        df_epochs['stage'] = stages\n",
    "    except Exception as ex:\n",
    "        print(ex)\n",
    "        pass\n",
    "\n",
    "    df_epochs = df.groupby('epoch').mean()\n",
    "    X, y = df_epochs.values, rejects\n",
    "    X, y_true = X, y\n",
    "    y_pred = clfSVC.predict(X)\n",
    "\n",
    "    print(\"\\tRecall: %1.3f\" % recall_score(y_true, y_pred))\n",
    "    print(\"\\tF1: %1.3f\\n\" % f1_score(y_true, y_pred))"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
